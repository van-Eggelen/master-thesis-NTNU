{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b97c409f-1abe-47f6-b0ad-6bef6450df19",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Methods used in several Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cbe6f4f-a800-4454-9110-2502e6a87102",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd #required for most of the methods below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fcc9bfc-927b-4a79-8b82-c45e167a7017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mariekececilia/Documents/master_thesis_code'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pathway of the folder of this file\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983af36a-a24f-4664-a4b7-9133071c3aae",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47291054-8660-4303-b24f-90fa610d5f71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Load both datasets (transcriptomics/features and fluxomics/targets) from Gerosa\n",
    "def load_gerosa():\n",
    "    data_folder_path = '/Users/mariekececilia/Documents/master_thesis_code/Data/'\n",
    "    transcriptomics_path = data_folder_path + 'gerosa_2015_transcriptomics.csv';\n",
    "    fluxomics_path = data_folder_path + 'gerosa_2015_fluxomics.csv'; \n",
    "    \n",
    "    # Load the datasets with the first columns (containing the description of the rows) as index and\n",
    "    # transpose it, because want conditions as observations and measurments as features/target\n",
    "    transcriptomics = pd.read_csv(transcriptomics_path, index_col=0).transpose();\n",
    "    fluxomics = pd.read_csv(fluxomics_path, index_col=0).transpose();\n",
    "    \n",
    "    return [transcriptomics, fluxomics]\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "#Load both datasets (transcriptomics/features and fluxomics/targets) from Ishii\n",
    "def load_ishii():\n",
    "    data_folder_path = '/Users/mariekececilia/Documents/master_thesis_code/Data/'\n",
    "    transcriptomics_path = data_folder_path + 'ishii_2007_transcriptomics.csv';\n",
    "    fluxomics_path = data_folder_path + 'ishii_2007_fluxomics.csv'; \n",
    "    \n",
    "    # Load the datasets with the first columns (containing the description of the rows) as index and\n",
    "    # transpose it, because want conditions as observations and measurments as features/target\n",
    "    transcriptomics = pd.read_csv(transcriptomics_path, index_col=0).transpose();\n",
    "    fluxomics = pd.read_csv(fluxomics_path, index_col=0).transpose();\n",
    "    \n",
    "    return [transcriptomics, fluxomics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ef2e35f-5e23-4dc5-8ed9-dae7b6a2ddc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split Ishii into two separate dataframes, one for each perturbation (growth rate and knockouts, the baseline WR_0.2h-1 is included in both)\n",
    "def split_ishii(df):\n",
    "    dilution_perturbations = ['WT_0.7h-1','WT_0.5h-1','WT_0.4h-1','WT_0.1h-1'];\n",
    "    baseline = 'WT_0.2h-1'\n",
    "    dilution = df.loc[dilution_perturbations + [baseline]]\n",
    "    knockout = df.drop(dilution_perturbations)\n",
    "    return [dilution, knockout]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040d2089-5e4b-48f0-8794-153a81c46ba1",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b450675-4aac-4eeb-801e-e78e455fa0fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Clean data (remove redundant and unfit columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd7d7cdb-6841-43c8-bb2b-699d2d0543d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicated genes and return dictionary of duplicates\n",
    "#(if any duplicated gene is shown to be important, the genes with the same measurements can be found using the returned dicitonary)\n",
    "def clean_gexp_g(df):\n",
    "    #locate all duplicates first to make it more efficient \n",
    "    duplicates = df.T[df.T.duplicated(keep = False)].T\n",
    "    #group the duplicates\n",
    "    equal_dict = get_equal_groups(duplicates)\n",
    "    #remove all but one from each group, i.e. remove all values:\n",
    "    extras = []\n",
    "    for key, value in equal_dict.items():\n",
    "        extras = extras + value\n",
    "    df = df.drop(extras, axis = 'columns')\n",
    "    #return dict of groupings so that the duplicates can easily be found later in the analysis\n",
    "    return df, equal_dict\n",
    "\n",
    "#Clean Gerosa: remove external reactions, constant reactions, reactions with many null-entries and duplicated reactions\n",
    "#return duplicates so that reactions that would give the same results can be looked up\n",
    "def clean_gerosa(df):\n",
    "    df = remove_ex_constant_zero(df)\n",
    "    df, equal_dict = remove_extras(df) \n",
    "    return df, equal_dict\n",
    "\n",
    "#Clean Ishii: remove external reactions, constant reactions, reactions with many null-entries and duplicated reactions\n",
    "#return duplicates so that reactions that would give the same results can be looked up\n",
    "def clean_ishii(df):\n",
    "    df = df.drop('R_GLCptspp', axis = 1) #also considered external\n",
    "    df = remove_ex_constant_zero(df)\n",
    "    df, equal_dict = remove_extras(df)\n",
    "    return df, equal_dict\n",
    "    \n",
    "# -----------------------------------------------------------------\n",
    "#remove exchange reactions, constant reactions and reactions with many null-entries\n",
    "def remove_ex_constant_zero(df):\n",
    "    \n",
    "    #remove exchange reactions:\n",
    "    ex = get_ex(df)\n",
    "    df = df.drop(ex, axis = 1)\n",
    "    \n",
    "    #remove constant reactions:\n",
    "    constant = df.nunique()[df.nunique() == 1].index.tolist()\n",
    "    df = df.drop(constant, axis = 1)\n",
    "    \n",
    "    #remove reactions where more than half of the entries are zero\n",
    "    mostly_zero = get_mostly_zero(df)\n",
    "    df = df.drop(mostly_zero, axis = 1)\n",
    "    return df\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "#get exchange reactions\n",
    "def get_ex(df):\n",
    "    ex = []\n",
    "    for reaction in df.columns:\n",
    "        if '_EX_' in reaction:\n",
    "            ex.append(reaction)\n",
    "    return ex\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "#get reactions where more than half of the entries are zero\n",
    "def get_mostly_zero(df):\n",
    "    total = df.shape[0]\n",
    "    mostly_zero = []\n",
    "    for reaction in df.columns:\n",
    "        if ((df[reaction] == 0).sum() > (total/2)):\n",
    "            mostly_zero.append(reaction)\n",
    "    return mostly_zero\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# remove duplicates and return a dictionary of the them\n",
    "def remove_extras(df):\n",
    "    equal_dict = get_equal_or_mirrored_groups(df)\n",
    "    for key, value in equal_dict.items():\n",
    "        df = df.drop(value, axis = 1)\n",
    "    return df, equal_dict\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "#                FIND AND GROUP DUPLICATES\n",
    "# -----------------------------------------------------------------\n",
    "\"\"\"\n",
    "Identify columns in a dataframe with equal/mirrored (multiplied by -1) \n",
    "measurements and group them. The key for each group is the first label\n",
    "in alphabetical order, the remaining labels are put in the value set. \n",
    "\"\"\"\n",
    "def get_equal_or_mirrored_groups(df): \n",
    "    \n",
    "    #storage\n",
    "    group_dict = {}\n",
    "    \n",
    "    #loop through all pairs of columns\n",
    "    labels = df.columns.tolist()    \n",
    "    for i in range(len(labels)):\n",
    "        L1 = labels[i]\n",
    "        for j in range(i+1, len(labels)):\n",
    "            #break the loop when at the end\n",
    "            if i == len(labels)-1:\n",
    "                break\n",
    "            L2 = labels[j]\n",
    "            \n",
    "            #compare measurements (sum and differences)\n",
    "            zero_if_equal = pd.Series(df[L1]-df[L2]) \n",
    "            zero_if_mirrored = pd.Series(df[L1]+df[L2])            \n",
    "            if ((zero_if_equal.sum() == 0) | (zero_if_mirrored.sum() == 0)):\n",
    "                \n",
    "                #register/add to relationship group                 \n",
    "                group_dict = update_groups(L1, L2, group_dict) \n",
    "                \n",
    "    return sort_dict_pairs(group_dict)\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "Identify columns in a dataframe with equal measurements and group them. \n",
    "The key for each group is the first label in alphabetical order, the \n",
    "remaining labels are put in the value set. \n",
    "\"\"\"\n",
    "def get_equal_groups(df): \n",
    "    \n",
    "    #storage\n",
    "    group_dict = {}\n",
    "    \n",
    "    #loop through all pairs of columns\n",
    "    labels = df.columns.tolist()    \n",
    "    for i in range(len(labels)):\n",
    "        L1 = labels[i]\n",
    "        for j in range(i+1, len(labels)):\n",
    "            #break the loop when at the end\n",
    "            if i == len(labels)-1:\n",
    "                break\n",
    "            L2 = labels[j]\n",
    "            \n",
    "            #create a series of their differences\n",
    "            zero_if_equal = pd.Series(df[L1]-df[L2]) \n",
    "            \n",
    "            #check sum of the series to identify those that are equal\n",
    "            if (zero_if_equal.sum() == 0):\n",
    "                \n",
    "                #register/add to relationship group                 \n",
    "                group_dict = update_groups(L1, L2, group_dict) \n",
    "                \n",
    "    return sort_dict_pairs(group_dict)\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "Add overlapping relationships to an exisiting dictionary of relationships.\n",
    "The key of a group is random among its members; the first instance of a group \n",
    "is mapped to a set of the other instances \n",
    "\"\"\"\n",
    "def update_groups(label_1, label_2, group_dict):\n",
    "    \n",
    "    #if one is registerede before, add the other in the correct group\n",
    "    if label_1 in group_dict.keys():\n",
    "        group_dict[label_1].add(label_2)\n",
    "    elif label_2 in group_dict.keys():\n",
    "        group_dict[label_2].add(label_1)\n",
    "    \n",
    "    #if neither are reigstered as keys, check if they are registered as \n",
    "    #a value of a third key\n",
    "    else:\n",
    "        match = 'NaN'\n",
    "        # loop through all value sets and their corresponding key\n",
    "        for value, key in zip(group_dict.values(), group_dict.keys()):\n",
    "            if (label_1 in value or label_2 in value):\n",
    "                match = key\n",
    "                break\n",
    "        #register a new relationship if no match was found\n",
    "        if match == 'NaN':\n",
    "            group_dict[label_1] = set([label_2])\n",
    "        #otherwise, add the new value to the value set of the match\n",
    "        else:\n",
    "            #one is added previously but that does not matter since sets \n",
    "            #only accept new values \n",
    "            group_dict[match].add(label_1)\n",
    "            group_dict[match].add(label_2)\n",
    "                    \n",
    "    return group_dict\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "Sort a dictionary that groups realtionships so that the key for each group \n",
    "is the first label in alphabetical order, while the remaining labels are in \n",
    "the value set. \n",
    "\"\"\"\n",
    "def sort_dict_pairs(my_dict):\n",
    "    new_dict = {}\n",
    "    for key, value in my_dict.items():\n",
    "        value.add(key)\n",
    "        temp = sorted(value)\n",
    "        new_key = temp.pop(0)\n",
    "        new_dict[new_key] = temp\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de1496a-7f44-4188-99ef-21c9850f3dcb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Standardize data (center and scale to unit variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fb87c27-0363-4bb6-b439-1079dbd10ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "'''\n",
    "Wrapper method which returns the scaled entries (mean = 0, variance = 1) by StandardScaler in a dataframe \n",
    "NB! sklearn uses numpy so the standardization uses a different ddof than the default in pandas. Therefore\n",
    "the variance of the returned features is not 1 if you calculate it with the pandas default, but it is if \n",
    "you set the ddof parameter to 0.\n",
    "'''\n",
    "def standardize(df):\n",
    "    scaler = StandardScaler()\n",
    "    scaled_df = StandardScaler().fit_transform(df)\n",
    "    scaled_df = pd.DataFrame(scaled_df, columns = df.columns, index = df.index)\n",
    "    return(scaled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910bdd05-3620-465f-9ad1-04d539135e13",
   "metadata": {},
   "source": [
    "## Explore data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f151265b-13b7-4b0d-95ce-6e4040b641b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Intersecion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b90bdcc8-8140-4cf2-b205-2589ddc14cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the intersection of columns of two dataframes\n",
    "def get_intersection(df1, df2):\n",
    "    intersect = []\n",
    "    for col in df1.columns:\n",
    "        if col in df2.columns:\n",
    "            intersect.append(col)\n",
    "    return intersect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08028706-7ca4-4855-9c61-9d56eb5e3e27",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1994b1bd-b589-4032-9c4e-db3c9ddb6ff2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from scipy.stats import spearmanr\n",
    "\n",
    "\"\"\"\n",
    "Calculate Spearman's correlation rank between all pairs of columns from two dataframes. \n",
    "Returns a dataframe with the labels, the rank, and, if chosen, the p-value \n",
    "-> set column_names accordingly. \n",
    "\"\"\"\n",
    "def get_all_correlations(df_1, df_2, column_names = ['col_1', 'col_2', 'r'], p_val = False):\n",
    "    \n",
    "    corr = []\n",
    "    \n",
    "    for col_1 in df_1.columns:\n",
    "        for col_2 in df_2.columns:\n",
    "            \n",
    "            r, p = spearmanr(df_1[col_1], df_2[col_2])\n",
    "            corr.append((col_1, col_2, r, p)) if (p_val) else corr.append((col_1, col_2, r))\n",
    "            \n",
    "    corr_df = pd.DataFrame(corr, columns = column_names);\n",
    "    return corr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b7638c-b5f5-405b-b8d2-a30dbb0d8412",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Convert gene b-numbers to common names "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c660215c-0aca-4bd6-b602-f3bdf3d7f891",
   "metadata": {},
   "source": [
    "Exported table from https://biocyc.org/group?id=biocyc13-24029-3731963750 at 23.05.2022\n",
    "<br> 4665 rows of all-genes from Escherichia coli K-12 substr. MG1655\n",
    "<br> Owner: Peter Midford, Created: 05-Apr-2018 17:35:50, Last Modified: 05-Apr-2018 18:05:31, Readable by everyone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3633821-1a53-4271-9c4b-8e7699122c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dictionaries to look up conversion from b-number to common name (or the opposite way, useful in the Ishii KO case). \n",
    "\n",
    "def get_id_dicts(data):\n",
    "    print('Keep in mind that:')\n",
    "    print('* The conversion table used was for a differnt K-12 substrain: MG1655')\n",
    "\n",
    "    #load convertion table\n",
    "    folder_path_data = '/Users/mariekececilia/Documents/master_thesis_code/Data/'\n",
    "    id_table_path = folder_path_data + \"id_table.txt\"\n",
    "\n",
    "    #only extract the columns with the common names and b-numbers, and rename them\n",
    "    id_table = pd.read_csv(id_table_path, sep='\\t', lineterminator='\\n', usecols=range(2), dtype=\"string\") #index_col = 0\n",
    "    id_table = id_table.rename(columns = {'Accession-1': 'b_number', 'Gene Name' : 'common_name'})\n",
    "\n",
    "    #remove rows with NAN b-numbers\n",
    "    id_table = id_table[id_table['b_number'].notna()]\n",
    "\n",
    "    #remove rows with b-numbers not present in the data-set\n",
    "    id_table = id_table[id_table['b_number'].map(lambda x: True if x in data.columns else False)]\n",
    "    \n",
    "    #remove duplicates of common-names:\n",
    "    duplicated_common_names = id_table[id_table['common_name'].duplicated(keep = False)]\n",
    "    if (len(duplicated_common_names)>0):\n",
    "        print('* only one of these duplicated common names were kept:')\n",
    "        print(duplicated_common_names)\n",
    "        to_drop = id_table[id_table['common_name'].duplicated()].index.tolist()\n",
    "        id_table = id_table.drop(to_drop, axis = 'index')\n",
    "    \n",
    "    #remove duplicates of b-numbers:\n",
    "    duplicated_numbers = id_table[id_table['b_number'].duplicated(keep = False)]\n",
    "    if (len(duplicated_numbers)>0):\n",
    "        print('* only one of these duplicated b numbers were kept:')\n",
    "        print(duplicated_numbers)\n",
    "        to_drop = id_table[id_table['b_number'].duplicated()].index.tolist()\n",
    "        id_table = id_table.drop(to_drop, axis = 'index')\n",
    "\n",
    "    #set index to common name\n",
    "    id_table = id_table.set_index('common_name')\n",
    "        \n",
    "    #add missing b-numbers so that they can be looked up\n",
    "    print(\"* 'Following b-numbers had no match in the conversion table and are mapped to 'unsure' names:'\")\n",
    "    count = 1\n",
    "    for number in data.columns:\n",
    "        if number not in id_table['b_number'].tolist():\n",
    "            name = 'unsure_' + str(count)\n",
    "            print('\\t- ' + number + ' -> ' + name)\n",
    "            id_table.loc[name] = number\n",
    "            count = count+1\n",
    "    if count == 1:\n",
    "        print('\\t- None')\n",
    "\n",
    "    #make dictionary from dataframe with common name (index) as key\n",
    "    common_name_dict = id_table['b_number'].to_dict()\n",
    "    #swap index and column to make a dictionary with b-number as key instead\n",
    "    b_number_dict = id_table.reset_index().set_index('b_number')['common_name'].to_dict()    \n",
    "    return [common_name_dict, b_number_dict]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402f8f26-be9b-42f8-9c3a-e0141b6672a6",
   "metadata": {},
   "source": [
    "## ML with LOOCV (leave one out cross validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd7c5394-4f1d-454f-8b5e-44124da78671",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "#get the order of which samples were left out during LOOCV\n",
    "def get_loo_order(X):\n",
    "    loo = LeaveOneOut()\n",
    "    test_labels = []\n",
    "    #loop through arries of train and test indicies\n",
    "    for train, test in list(loo.split(X)):\n",
    "        #extract the test label through the test index\n",
    "        test_labels.append(X.index.tolist()[test[0]])\n",
    "    return test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b735a53b-9a61-4b66-addf-a30721820055",
   "metadata": {},
   "source": [
    "### Select by coefficiant of variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3100e6d2-c7e3-44a2-b327-e4acb5032f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin #must import to allow construction\n",
    "\n",
    "#a class that select features based on a coefficient of variation threshold\n",
    "class CoVSelector(BaseEstimator, TransformerMixin ):\n",
    "\n",
    "    #Class Constructor \n",
    "    def __init__(self, p):\n",
    "        self.p = p\n",
    "        self._feature_names = None \n",
    "\n",
    "    #Fit to data: find labels of features with high enough cov\n",
    "    def fit( self, X, y = None ):\n",
    "        cov = X.std()/X.mean()\n",
    "        self._feature_names = cov[cov> self.p].index\n",
    "        return self \n",
    "\n",
    "    #Transform data: extract features identified under fitting\n",
    "    def transform( self, X, y = None):        \n",
    "        return X[ self._feature_names ]\n",
    "    \n",
    "    #Method to make it similar to SelectKBest\n",
    "    def get_feature_names_out(self, X = None):\n",
    "        return self._feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b79b67-658a-4a35-b335-0486315f5245",
   "metadata": {},
   "source": [
    "### Get model scores (evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "362204f0-b99d-4a97-8e85-5c92c77b85c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import cross_val_score\n",
    "#from sklearn.model_selection import LeaveOneOut\n",
    "#import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "compare MAPE when using different models (pipelines) on the same set of features\n",
    "models is a dict of {names: corresponding models (pipelines)}\n",
    "\"\"\"\n",
    "def compare_models(models, X, y, description = 'Models'):\n",
    "    # create df to store all cv scores of each model\n",
    "    test_labels = get_loo_order(X)\n",
    "    cv_results =  (pd.DataFrame(index = test_labels)\n",
    "                  .rename_axis('Test set')\n",
    "                  .rename_axis(description, axis='columns'))\n",
    "    \n",
    "    # store summaries of ech model\n",
    "    names, means, stds = [], [], []\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        # evaluate model with CV and store scores as new column\n",
    "        scores = evaluate_model(model, X, y)\n",
    "        cv_results[name] = scores\n",
    "        # add summaries to lists\n",
    "        [mean, std] = summarise_scores(scores)\n",
    "        names.append(name)\n",
    "        means.append(mean)\n",
    "        stds.append(std)\n",
    "        \n",
    "    #create summary df from lists\n",
    "    summary = pd.DataFrame(data = zip(means, stds), \n",
    "                           index = names,\n",
    "                           columns = ['average', 'std']).rename_axis(description)\n",
    "    return [cv_results, summary]\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    loo = LeaveOneOut()\n",
    "    scores = cross_val_score(model, X, y, \n",
    "                             scoring = 'neg_mean_absolute_percentage_error',\n",
    "                             cv=loo, error_score='raise') \n",
    "    scores = scores * (-1) #counteract the negative MAPE scores\n",
    "    return scores\n",
    "\n",
    "#get mean and std of CV scores\n",
    "def summarise_scores(scores):\n",
    "    mean = np.mean(scores)\n",
    "    std = np.std(scores)\n",
    "    return [mean, std]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0285bb-3b9e-408b-9d63-963088bd0110",
   "metadata": {},
   "source": [
    "### Get model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fad951e-f960-447b-b9b2-8292455a9620",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import cross_val_predict\n",
    "#from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "\"\"\"\n",
    "Get predictions of each test sample in LOOCV for different models (pipelines) on the same set of features\n",
    "models is a dict of {names: corresponding models (pipelines)}\n",
    "\"\"\"\n",
    "def get_models_preds(models, X, y):\n",
    "    #find loo order (order of predicted samples)\n",
    "    preds = pd.DataFrame(index = get_loo_order(y))\n",
    "    #add actual values\n",
    "    preds['actual'] = y #rises error if index do not match loo order\n",
    "    #get and add predictions of each model\n",
    "    for name, m in models.items():\n",
    "        pred = prediction_from_model(m, X, y)\n",
    "        preds[name] = pred\n",
    "    return preds\n",
    "\n",
    "#get all predictions from a model (pipeline) with loocv\n",
    "def prediction_from_model(model, X, y):\n",
    "    loo = LeaveOneOut()\n",
    "    pred = cross_val_predict(model, X, y, cv=loo) \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f8eefe-31a9-47c8-bf16-2023a09be131",
   "metadata": {},
   "source": [
    "### Get the selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d7508d0-ae75-48a1-827f-f617115e5efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "#        Extract selected features from the different CV iterations\n",
    "# ------------------------------------------------------------------------\n",
    "\"\"\"\n",
    " Get selected features and their corresponding coefficients, returned in two dicts: \n",
    "   [sample left out] -> list of features selected when that sample is left out}\n",
    "   [sample left out] -> list of coefficients of features selected when that sample is left out}\n",
    "   \n",
    "   must do the CV manually in order to extract the selected features\n",
    "\"\"\"\n",
    "def get_loo_selected_feature_names_and_coef(pipeline, X, y):\n",
    "    \n",
    "    #find order of test samples left out\n",
    "    loo_order = get_loo_order(X)\n",
    "    \n",
    "    #get selected features and their coefficients when sample left out\n",
    "    selected_dict = dict()\n",
    "    coef_dict = dict()\n",
    "    for test_sample in loo_order:\n",
    "        \n",
    "        #fit with split data\n",
    "        X_train = X.drop(test_sample)\n",
    "        y_train = y.drop(test_sample)\n",
    "        fitted = pipeline.fit(X_train,y_train)\n",
    "        \n",
    "        #get selecetions and coef\n",
    "        selected_dict[test_sample] = fitted[:-1].get_feature_names_out()\n",
    "        coef_dict[test_sample] = fitted[-1].coef_\n",
    "        \n",
    "    return selected_dict, coef_dict\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "#  Create dataframes of selected features in the different CV splits\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "\"\"\"\n",
    "Create dataframes from the features-coef pairs for each split, ordered\n",
    "by their importance. The lower the order, the higher absolute coefficant.\n",
    "One method to get all individual dataframes and one to get a merged\n",
    "dataframe that allows more analysis (times selected etc.). \n",
    "\"\"\"\n",
    "\n",
    "# create dataframe of selected features and their coefficients, one for each CV split\n",
    "def get_loo_selected_features_and_coef_df(selected_dict, coef_dict):\n",
    "    \n",
    "    df_dict = dict()\n",
    "    \n",
    "    for test_sample in selected_dict.keys():\n",
    "        features = selected_dict[test_sample]\n",
    "        coef = coef_dict[test_sample]\n",
    "        df = pd.DataFrame([features, coef], index = ['feature', 'coef']).T\n",
    "        df = order_selected_features_by_coef(df)\n",
    "        df_dict[test_sample] = df\n",
    "    return df_dict\n",
    "\n",
    "# create one dataframe of selected features and their coefficients in all CV splits\n",
    "def get_loo_selected_features_and_coef_df_merged(selected_dict, coef_dict):\n",
    "        \n",
    "    selected = []\n",
    "    first = True\n",
    "    \n",
    "    #turn each set of features and coef into df\n",
    "    for test_sample in selected_dict.keys():\n",
    "        features = selected_dict[test_sample]\n",
    "        coef = coef_dict[test_sample]\n",
    "        df = pd.DataFrame([features, coef], index = ['feature', 'coef']).T\n",
    "        df = order_selected_features_by_coef(df)\n",
    "        \n",
    "        #merge with the other dataframes\n",
    "        if first:\n",
    "            cols = df.columns.tolist()\n",
    "            df['sample left out'] = test_sample\n",
    "            selected = df\n",
    "            first = False\n",
    "        else:\n",
    "            df['sample left out'] = test_sample\n",
    "            selected = pd.concat([selected, df])\n",
    "            \n",
    "    return selected[(['sample left out']+cols)]\n",
    "\n",
    "#add a order column and sort by this one\n",
    "def order_selected_features_by_coef(df):\n",
    "    #sort by abs value\n",
    "    df['abs'] = df['coef'].abs()\n",
    "    df = df.sort_values(by = 'abs', ascending = False)\n",
    "    #re-index to get index by sorted order\n",
    "    df = df.reset_index()\n",
    "    df['order'] = df.index\n",
    "    #put original index back\n",
    "    df = df.set_index('index')\n",
    "    return df.drop('abs', axis = 1)\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "#   Analyse number/set of selected features in the different CV splits\n",
    "# ------------------------------------------------------------------------    \n",
    "\"\"\"\n",
    "Get list of features in intersection and list of features in union of\n",
    "slected features (one set of selected features per CV iteration)\n",
    "\"\"\"\n",
    "def get_selected_features_intersection_and_union(selected_dict):\n",
    "    #make list of list\n",
    "    all_subsets= []\n",
    "    for value in selected_dict.values(): \n",
    "        all_subsets.append(value)\n",
    "        \n",
    "    #get intersection and union of all lists in list of lists\n",
    "    intersection = set(all_subsets[0]).intersection(*all_subsets)\n",
    "    union = set(all_subsets[0]).union(*all_subsets)\n",
    "\n",
    "    return dict({'intersection': intersection, 'union': union})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276afc91-91b2-4067-8a59-34893dd7c916",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4bee6a-dd6c-447a-a62c-9d82cd139ffc",
   "metadata": {},
   "source": [
    "### Remove empty subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89250369-0ccd-4158-a5f2-93b752c597f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#import math\n",
    "\n",
    "#remove empty subplots \n",
    "#NB! will remove the bottom plots and therefore the shared x-axis\n",
    "# -> cannot use sharex = True, but follow up with remove_xaxes (below)\n",
    "def remove_empty_subplots(fig, axes, nplots, nrows, ncols):\n",
    "    empty_plots = nrows*ncols-nplots\n",
    "    empty_rows = math.floor(empty_plots/ncols)\n",
    "    empty_cols = empty_plots-empty_rows*ncols\n",
    "    \n",
    "    if(empty_rows>0):\n",
    "        for i in range(nrows-empty_rows, nrows):\n",
    "            for j in range(ncols):\n",
    "                fig.delaxes(axes[i][j])\n",
    "    if(empty_cols>0):\n",
    "        for j in range(ncols-empty_cols, ncols):\n",
    "            fig.delaxes(axes[nrows-empty_rows-1][j])\n",
    "    return fig\n",
    "\n",
    "#removes x-axis from all but the last non-empty subplots in each column\n",
    "def remove_xaxes(axes, nplots, nrows, ncols):\n",
    "    empty_plots = nrows*ncols-nplots\n",
    "    empty_rows = math.floor(empty_plots/ncols)\n",
    "    empty_cols = empty_plots-empty_rows*ncols\n",
    "    last_row = nrows-empty_rows-1\n",
    "    \n",
    "    if((empty_cols>0) & (last_row>0)):\n",
    "        for i in range(0, last_row):\n",
    "            if i == last_row-1:\n",
    "                for j in range(0, ncols-empty_cols):\n",
    "                    #axes[i][j].set_xticks([])\n",
    "                    axes[i][j].set_xticklabels([])\n",
    "                    axes[i][j].set_xlabel('')\n",
    "            else:\n",
    "                for j in range(0, ncols):\n",
    "                    #axes[i][j].set_xticks([])\n",
    "                    axes[i][j].set_xticklabels([])\n",
    "                    axes[i][j].set_xlabel('')\n",
    "    if ((empty_cols == 0) & (last_row>0)):\n",
    "        for i in range(0, last_row):\n",
    "            for j in range(0, ncols):\n",
    "                #axes[i][j].set_xticks([])\n",
    "                axes[i][j].set_xticklabels([])\n",
    "                axes[i][j].set_xlabel('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277731bc-b73b-42b0-8c6b-87ecbd83afa9",
   "metadata": {},
   "source": [
    "### Box plots of scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfe85eaf-bdd6-46b7-ba43-6c357c04a8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "#draw boxplot subplots with some added defaults\n",
    "def draw_box_subplots(cv_results, \n",
    "                      names, \n",
    "                      ax = None, \n",
    "                      xlab = 'Model', \n",
    "                      ylab = 'MAPE',\n",
    "                      showmeans=True,\n",
    "                      patch_artist=True,\n",
    "                      boxprops=dict(facecolor='lightblue', \n",
    "                                    color='lightblue'),\n",
    "                      meanprops = dict(markeredgecolor='darkgreen', \n",
    "                                       markerfacecolor='darkgreen', \n",
    "                                       markersize = '5'),\n",
    "                      #medianprops=dict(color='purple'),\n",
    "                      **kwargs):\n",
    "    ax.boxplot(cv_results, \n",
    "               labels=names,\n",
    "               showmeans=showmeans,\n",
    "               patch_artist = patch_artist,\n",
    "               boxprops=boxprops,\n",
    "               meanprops = meanprops,\n",
    "               #medianprops=medianprops,\n",
    "               **kwargs)\n",
    "    ax.set_ylabel(ylab)\n",
    "    ax.set_xlabel(xlab)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2a2123-ff53-465e-ac11-5de99055b83d",
   "metadata": {},
   "source": [
    "### Predicted vs actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2e4217d-5dd6-4788-8c09-bbead5839244",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import seaborn as sns\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "#draw scatter plots of Actual values vs predicted values (as subplots)\n",
    "def plot_preds(x, y, data, min_lim = 0, max_lim = 4, ax=None, diagonal = True, **kwargs):\n",
    "    if (diagonal):\n",
    "        ax.plot([min_lim, max_lim], [min_lim,max_lim], linestyle = 'dotted', color = 'grey', alpha = 0.5)\n",
    "    sns.scatterplot(x=x, y=y, data=data, ax = ax, **kwargs)\n",
    "    ax.set_title(x)\n",
    "    ax.set_ylabel('Actual value')\n",
    "    ax.set_xlabel('Predicted value')\n",
    "    ax.set_xlim(min_lim, max_lim)\n",
    "    ax.set_ylim(min_lim, max_lim)\n",
    "    if (ax.get_legend() != None):\n",
    "        ax.get_legend().remove()\n",
    "    return ax"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
